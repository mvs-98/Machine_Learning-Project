{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Specification\n",
        "\n",
        "For this project we will perform **THREE** short questions which cover the breadth of the machine learning module along with attempting **ONE** of the four longer project-style questions. All of the short tasks and longer project-style questions can be found in this notebook.\n",
        "\n",
        "The learning objectives of these short questions are:\n",
        "- To demonstrate a wide-range of machine learning skills.\n",
        "- To be able to apply the most appropriate approach at the right time."
      ],
      "metadata": {
        "id": "bbN5C3u52T3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Question 1: Classification (10 marks)\n",
        "\n",
        "Load the dataset below, where X and y are the feature (input) variables and target (output) variable. Based on this dataset, build TWO classifiers using different machine learning approaches to predict the two classes in the target variable. You are free to use any appropriate machine learning models and libraries, but you need to split the dataset into training and test sets and optimise the model's hyperparameters (e.g. using GridSearchCV()). As a result, the performance metrics of the best classifier should be reported over the test set. Please follow the steps below to complete the code.\n",
        "\n",
        "The dataset is available at:\n",
        "https://ncl.instructure.com/courses/53509/files/7659751?wrap=1 and\n",
        "https://ncl.instructure.com/courses/53509/files/7659755?wrap=1\n"
      ],
      "metadata": {
        "id": "TP7dNS643CwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the environment and load the dataset"
      ],
      "metadata": {
        "id": "nm8C4PpFrHIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just run this cell, don't change the code\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "X = loadtxt('cls_X.csv', delimiter=',')\n",
        "y = loadtxt('cls_y.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "OZxqzi0vrNlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1.1 Split the data into training and test sets (20% for testing)"
      ],
      "metadata": {
        "id": "i_CnC7pLrUnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below to replace the ellipsis \"...\"\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data and keep 20% for testing purpose by specifying test_size as 0.2\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X1_train.shape)\n",
        "print(\"X_test shape:\", X1_test.shape)\n",
        "print(\"y_train shape:\", y1_train.shape)\n",
        "print(\"y_test shape:\", y1_test.shape)"
      ],
      "metadata": {
        "id": "E7_KCvHbrbX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b2f416-ed16-43d4-e1e8-15eb4b880f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (320, 6)\n",
            "X_test shape: (80, 6)\n",
            "y_train shape: (320,)\n",
            "y_test shape: (80,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1.2 Create your first classifier"
      ],
      "metadata": {
        "id": "9hNfN-wfrpy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1.2.1 First, make an attempt by using an appropriate machine learning method without optimising the hyperparameter(s). Report the model accuracy over the test set (i.e. test accuracy)."
      ],
      "metadata": {
        "id": "MoIln9tQrziM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below to replace the ellipsis \"...\"\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Creating the instance of support vector classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Fitting the training data in order to train the model\n",
        "svm.fit(X1_train, y1_train)\n",
        "\n",
        "# Making predictions based on testing data\n",
        "svm_predictions = svm.predict(X1_test)\n",
        "\n",
        "# Evaluating performance of the model by checking its accuracy\n",
        "print(\"SVM Performance:\")\n",
        "print(\"Accuracy of support vector machine: \", accuracy_score(y1_test, svm_predictions))"
      ],
      "metadata": {
        "id": "M8B7NYQer40j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b4e28a-0291-4906-c21f-7584ce6e1851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Performance:\n",
            "Accuracy of support vector machine:  0.8875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1.2.2 Then, optimise the hyperparameter(s) using the same machine learning method as above. Report the best hyperparameter(s) and, use it to make your first classifier and print out its test accuracy."
      ],
      "metadata": {
        "id": "Qv4TGRbir9Qj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below to replace the ellipsis \"...\"\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Creating the instance of support vector classifier\n",
        "svm = SVC()\n",
        "\n",
        "# Defining the parameter grid of hyperparameters to optimize\n",
        "param_grid = {'C': [0.1, 10, 100], 'gamma': ['scale', 'auto'], 'kernel': ['linear', 'rbf']}\n",
        "\n",
        "# Fitting the grid search to the data\n",
        "svm_grid = GridSearchCV(svm, param_grid, cv=5)\n",
        "svm_grid.fit(X1_train, y1_train)\n",
        "\n",
        "# Searching for the best hyperparameters and printing them\n",
        "best_parameters = svm_grid.best_params_\n",
        "print(\"Best Hyperparameters found:\", best_parameters)\n",
        "\n",
        "# Use the best parameters found to create optimized SVM\n",
        "optimized_svm = SVC(**best_parameters)\n",
        "optimized_svm.fit(X1_train, y1_train)\n",
        "\n",
        "# Making predictions on the testing data\n",
        "optimized_svm_predictions = optimized_svm.predict(X1_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"\\nSVM Performance with Best Hyperparameters:\")\n",
        "print(\"Accuracy of optimized support vector machine: \", accuracy_score(y1_test, optimized_svm_predictions))"
      ],
      "metadata": {
        "id": "py6TTQBbsN2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a921fee6-1bde-444e-b8c0-d0744e02cb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters found: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "\n",
            "SVM Performance with Best Hyperparameters:\n",
            "Accuracy of optimized support vector machine:  0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1.3 Create your second classifier"
      ],
      "metadata": {
        "id": "a9vtXIavsR3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1.3.1 First, without optimising the hyperparameter(s), make an attempt by using a different machine learning method to the first classifier. Report the model accuracy over the test set (i.e. test accuracy)."
      ],
      "metadata": {
        "id": "7e2hW5LosXij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below to replace the ellipsis \"...\"\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Creating an instance of KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Training the algorithm with help of training set\n",
        "knn.fit(X1_train, y1_train)\n",
        "\n",
        "# Prediction on the testing data\n",
        "knn_pred = knn.predict(X1_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Accuracy of KNN with 3 nearest neighbours: {accuracy_score(y1_test, knn_pred)}\")"
      ],
      "metadata": {
        "id": "xOdf70l6sdB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fc7986-d3b9-41a4-e10b-80e94318627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of KNN with 3 nearest neighbours: 0.8875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1.3.2 Then, optimise the hyperparameter(s) using the same machine learning method as above. Report the best hyperparameter(s) and, use it to make your second classifier and print out its test accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "oEkKujVhshwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below to replace the ellipsis \"...\"\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Creating an instance of KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Defining the parameter grid of hyperparameters to optimize\n",
        "parameter_grid = {'n_neighbors': [1, 4, 6], 'p': [1, 2]}\n",
        "\n",
        "# Fitting the grid search to the data\n",
        "knn_grid_search = GridSearchCV(estimator=knn, param_grid=parameter_grid, cv=5, scoring='accuracy')\n",
        "knn_grid_search.fit(X1_train, y1_train)\n",
        "\n",
        "# Searching the best hyperparameter(s) and printing them\n",
        "knn_best_parameters = knn_grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", knn_best_parameters)\n",
        "\n",
        "# Using the best model for prediction\n",
        "optimized_knn = KNeighborsClassifier(**knn_best_parameters)\n",
        "optimized_knn.fit(X1_train, y1_train)\n",
        "\n",
        "# Making predictions on the testing data\n",
        "optimized_knn_predictions = optimized_knn.predict(X1_test)\n",
        "\n",
        "# Calculate accuracy using the best model\n",
        "print(f\"\\nAccuracy of optimized KNN with best parameters: {accuracy_score(y1_test, optimized_knn_predictions)}\")"
      ],
      "metadata": {
        "id": "9A7qo9PEsmyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c96bf2d-21b7-4be0-e832-df0d5e86c787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_neighbors': 4, 'p': 2}\n",
            "\n",
            "Accuracy of optimized KNN with best parameters: 0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1.4 Report the precision, recall, f1 score and confusion matrix on the best of the two classifiers"
      ],
      "metadata": {
        "id": "7b0F3CHOstgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code below to replace the ellipsis \"...\"\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Calculating precision, recall, and F1-score of optimized KNN algorithm\n",
        "precision = precision_score(y1_test, optimized_knn_predictions)\n",
        "recall = recall_score(y1_test, optimized_knn_predictions)\n",
        "f1 = f1_score(y1_test, optimized_knn_predictions)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cf_matrix = confusion_matrix(y1_test, optimized_knn_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cf_matrix)"
      ],
      "metadata": {
        "id": "b8xcn_ZPsyhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2389966a-0bfe-4c3b-d272-1f48b6be6c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9523809523809523\n",
            "Recall: 0.9090909090909091\n",
            "F1-score: 0.9302325581395349\n",
            "Confusion Matrix:\n",
            "[[34  2]\n",
            " [ 4 40]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 2: Regression (10 marks)\n",
        "\n",
        "In this question you are given a simple dataset which you will perform regression on to predict values. You will build TWO Regression models and then take the best one and perform hyperparameter tuning on it.\n",
        "\n",
        "## Set up the environment"
      ],
      "metadata": {
        "id": "9gckRSHj3PdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "W-vFlRnBa2NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in the data\n",
        "\n",
        "You'll need to download the data.csv file from https://ncl.instructure.com/courses/53509/files/7657710?wrap=1 and upload it to your Google Drive. I placed it in a folder called data. Then you need to mount your Google Drive in Colab (cell below)."
      ],
      "metadata": {
        "id": "end1ynOha5cg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG7eucEW2RM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5cafd1-1b99-4063-866e-b8daa5a44bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then read in the data"
      ],
      "metadata": {
        "id": "WwYiqGNp9X_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt('/content/drive/MyDrive/data/data.csv', delimiter=',')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "pQRk-XkFa7ke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcc69c63-6468-4529-bacd-2e43103393d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00000000e+00 9.00000000e+00 2.57259990e+00 2.49788633e+02]\n",
            " [1.00000000e+00 5.00000000e+00 9.21413366e+00 5.04502032e+02]\n",
            " [1.00000000e+00 1.70000000e+01 7.12330090e+00 1.33580225e+03]\n",
            " ...\n",
            " [5.00000000e+00 3.10000000e+01 6.80121067e+00 3.15979690e+03]\n",
            " [5.00000000e+00 1.00000000e+01 4.14995662e+00 6.21315789e+02]\n",
            " [5.00000000e+00 9.00000000e+00 9.61878173e+00 1.30105857e+03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2.1 Split the data into X and y\n",
        "\n",
        "X is the first three columns\n",
        "\n",
        "y is the last column"
      ],
      "metadata": {
        "id": "xr0Wc-5za96b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your answer here\n",
        "\n",
        "# Splitting the data into X and y\n",
        "X = data[:,:3]\n",
        "y = data[:,3]\n",
        "# Printing the shape of X and y\n",
        "print(\"X: \", X.shape)\n",
        "print(\"y: \", y.shape)"
      ],
      "metadata": {
        "id": "uXqIfwSKbBQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50f4804-7aa4-4cdf-9647-4ee2654bb0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:  (1000, 3)\n",
            "y:  (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2.2 Create the Train and Test datasets\n",
        "\n",
        "20% of the data is kept back for testing"
      ],
      "metadata": {
        "id": "lWn0sY4MbGSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your answer here\n",
        "\n",
        "# Split the data into training and testing set\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Printing the shape of train and test data\n",
        "print(\"X_train shape:\", X2_train.shape)\n",
        "print(\"X_test shape:\", X2_test.shape)\n",
        "print(\"y_train shape:\", y2_train.shape)\n",
        "print(\"y_test shape:\", y2_test.shape)"
      ],
      "metadata": {
        "id": "MGffSN2bbKG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29d2229-8487-4e41-bd77-60bd535099d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (800, 3)\n",
            "X_test shape: (200, 3)\n",
            "y_train shape: (800,)\n",
            "y_test shape: (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2.3 Use TWO Regression approaches on the dataset\n",
        "\n",
        "In each case report the R^2 value against the test data."
      ],
      "metadata": {
        "id": "wmtjZE2qbJrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.3.1 Regression approach 1"
      ],
      "metadata": {
        "id": "zGk6m2CGbPZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach 1: Linear Regression."
      ],
      "metadata": {
        "id": "aSyCQpxtoArD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your answer here\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Creating an instance of linear regression\n",
        "linear_regression = LinearRegression()\n",
        "\n",
        "# Training the model using train set\n",
        "linear_regression.fit(X2_train, y2_train)\n",
        "\n",
        "# Making prediction on test data\n",
        "linear_prediction = linear_regression.predict(X2_test)\n",
        "\n",
        "# Evaluating the performance of the model\n",
        "linear_r2value = r2_score(y2_test, linear_prediction)\n",
        "print(\"R^2 value for Linear Regression: \", linear_r2value)"
      ],
      "metadata": {
        "id": "itckiAcAbS5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "963206f2-90d3-4522-d565-32a2ad31c27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 value for Linear Regression:  0.8625374681259913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.3.2 Regression approach 2"
      ],
      "metadata": {
        "id": "qsgsuh8zbTRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach 2: Decision Tree Regression"
      ],
      "metadata": {
        "id": "3j5dosFmqalt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your answer here\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Creating an instance of Decision Tree Regressor\n",
        "decisiontree_regression = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "\n",
        "# Training the model using train set\n",
        "decisiontree_regression.fit(X2_train, y2_train)\n",
        "\n",
        "# Predicting on the test data\n",
        "decisiontree_prediction = decisiontree_regression.predict(X2_test)\n",
        "\n",
        "# Evaluating the performance of the model\n",
        "decisiontree_r2value = r2_score(y2_test, decisiontree_prediction)\n",
        "print(\"R^2 value for Decision Tree Regression: \", decisiontree_r2value)"
      ],
      "metadata": {
        "id": "Qr6GfmwbbV5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b547a10-dbe4-4fe1-ad0a-a79e3121f38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 value for Decision Tree Regression:  0.916664211341809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2.4 Optimise the hyperparameters\n",
        "\n",
        "Take your best Regression approach from above and identify the best hyperparameters. Note as some Regression approaches have many hyperparameters you may limit yourself here to just THREE."
      ],
      "metadata": {
        "id": "m3JF75BVbb7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.4.1 Search for the best hyperparameters"
      ],
      "metadata": {
        "id": "BVEVAHb6BXRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your answer here\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "decisiontree_regression = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Defining the grid of hyperparameters to search\n",
        "tree_parameter_grid = {\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Fitting the grid search to the data\n",
        "tree_grid_search = GridSearchCV(estimator=decisiontree_regression, param_grid=tree_parameter_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "tree_grid_search.fit(X2_train, y2_train)\n",
        "\n",
        "# Getting the best parameters found by GridSearchCV\n",
        "tree_best_parameters = tree_grid_search.best_params_"
      ],
      "metadata": {
        "id": "8ijdArC8bc46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.4.2 Output the best hyperparameters found"
      ],
      "metadata": {
        "id": "UNW3xx80bUyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your answer here\n",
        "\n",
        "# Printing the best parameters found\n",
        "print(\"Best Hyperparameters found: \", tree_best_parameters)"
      ],
      "metadata": {
        "id": "XqeEdsTyBf4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e3ee2c-9d43-4f2c-e303-ccea9f8e845c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters found:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.4.3 Show the results for the best model"
      ],
      "metadata": {
        "id": "LRVDmIC5blNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your answer here\n",
        "\n",
        "# Creating the instance of DecisionTreeRegressor using best hyperparameters\n",
        "optimized_decisiontree_regression = DecisionTreeRegressor(**tree_best_parameters)\n",
        "\n",
        "# Training the optimized decision tree model with train set\n",
        "optimized_decisiontree_regression.fit(X2_train, y2_train)\n",
        "\n",
        "# Making predictions on testing data\n",
        "optimized_decisiontree_predictions = optimized_decisiontree_regression.predict(X2_test)\n",
        "\n",
        "# Evaluating the performance of optimized decision tree regression\n",
        "optimized_decisiontree_r2value = r2_score(y2_test, optimized_decisiontree_predictions)\n",
        "print(\"R^2 value for optimized Decision Tree Regression: \", optimized_decisiontree_r2value)"
      ],
      "metadata": {
        "id": "MO5YBeW3bmCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7b0907-cb8a-46ba-8a03-81f45c1b2dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 value for optimized Decision Tree Regression:  0.9823223105850983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 3: Deep Learning (10 marks)"
      ],
      "metadata": {
        "id": "srmm6k8N3bHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.1 For MNIST dataset, implement a deep learning model with 3 hidden layers with layer size: 128, 256, 50.\n"
      ],
      "metadata": {
        "id": "JGLqEuqrom65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.datasets import mnist\n",
        "import keras.utils as utils\n",
        "\n",
        "batch_size = 128\n",
        "nb_classes = 10\n",
        "im_dim = 784 # the total pixel number\n",
        "nb_epoch = 2"
      ],
      "metadata": {
        "id": "Qohr1fFl11AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(60000, im_dim)\n",
        "X_test = X_test.reshape(10000, im_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "Y_train = utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = utils.to_categorical(y_test, nb_classes)"
      ],
      "metadata": {
        "id": "gKJlUuXy2MpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644530a2-71e1-417c-d454-c626349d5db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write down your code about MLP model for question Q3.1 here\n",
        "# you should call your model 'model'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=im_dim,units=128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=50))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(units=nb_classes))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mzOgmZhH2YEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have implemented a MLP model with 3 hidden layers of size 128, 256 and 50."
      ],
      "metadata": {
        "id": "QVMim5vtX2Cy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add code to output your network structure"
      ],
      "metadata": {
        "id": "dSWAUZHhE2sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZG7FyBFb208l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90d1c6e-6af4-425b-950a-1c9f627212e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 128)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                12850     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 50)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 146864 (573.69 KB)\n",
            "Trainable params: 146864 (573.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for iterator, layer in enumerate(model.layers):\n",
        "    print(f\"Layer {iterator+1}: {layer.name} - Number of input dimensions: {layer.output_shape[0]} - Number of neurons: {layer.output_shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iRw7tik76py",
        "outputId": "515a3711-cff2-435b-f5eb-0b73a2d4aaa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1: dense - Number of input dimensions: None - Number of neurons: 128\n",
            "Layer 2: activation - Number of input dimensions: None - Number of neurons: 128\n",
            "Layer 3: dropout - Number of input dimensions: None - Number of neurons: 128\n",
            "Layer 4: dense_1 - Number of input dimensions: None - Number of neurons: 256\n",
            "Layer 5: activation_1 - Number of input dimensions: None - Number of neurons: 256\n",
            "Layer 6: dropout_1 - Number of input dimensions: None - Number of neurons: 256\n",
            "Layer 7: dense_2 - Number of input dimensions: None - Number of neurons: 50\n",
            "Layer 8: activation_2 - Number of input dimensions: None - Number of neurons: 50\n",
            "Layer 9: dense_3 - Number of input dimensions: None - Number of neurons: 10\n",
            "Layer 10: activation_3 - Number of input dimensions: None - Number of neurons: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model for just two epochs to show it works. All code provided - just run."
      ],
      "metadata": {
        "id": "g1TKigVc-q37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history = model.fit(X_train, Y_train, epochs=nb_epoch,\n",
        "                    validation_split = 0.2,\n",
        "                    batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "evaluation = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
      ],
      "metadata": {
        "id": "2l4j6djO0xPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5739cca-37ae-44c1-afe4-45245862a82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "375/375 [==============================] - 6s 12ms/step - loss: 0.5027 - accuracy: 0.8433 - val_loss: 0.1682 - val_accuracy: 0.9490\n",
            "Epoch 2/2\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2013 - accuracy: 0.9387 - val_loss: 0.1318 - val_accuracy: 0.9585\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1269 - accuracy: 0.9587\n",
            "Summary: Loss over the test dataset: 0.13, Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q 3.2 For MNIST dataset, implement a CNN model with only one 2D CNN layer as the hidden layer."
      ],
      "metadata": {
        "id": "P_QoG4wjo2-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_2Usx0x5AGf",
        "outputId": "b9bb1fc1-acbd-4098-8f4f-f6497634c3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write down your code about the CNN model of Q3.2 here\n",
        "# you should call your model 'model'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_rows, img_cols, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5UjhYfvX5OCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add code to output your network structure"
      ],
      "metadata": {
        "id": "lZpz9nRi5lj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zlhSLt6U5nLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ba0915-b039-46cf-b9f8-40e0254120b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                54090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54410 (212.54 KB)\n",
            "Trainable params: 54410 (212.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just train for two epochs to demonstrate that the network does work. Just run it."
      ],
      "metadata": {
        "id": "Z4mhkn4N5Tq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "              verbose=1, shuffle=True,\n",
        "              validation_split = 0.2)\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (score[0], score[1]))"
      ],
      "metadata": {
        "id": "wEkhYk7npCun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab809ac9-bf77-4ac2-ccef-5b26c1b9ae10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "375/375 [==============================] - 16s 41ms/step - loss: 0.4006 - accuracy: 0.8873 - val_loss: 0.1696 - val_accuracy: 0.9523\n",
            "Epoch 2/2\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.1406 - accuracy: 0.9610 - val_loss: 0.1156 - val_accuracy: 0.9684\n",
            "Summary: Loss over the test dataset: 0.12, Accuracy: 0.97\n"
          ]
        }
      ]
    }
  ]
}